[{"path":"https://knowusuboaky.github.io/RAGFlowChainR/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Kwadwo Daddy Nyame Owusu Boakye Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kwadwo Daddy Nyame Owusu Boakye. Author, maintainer.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Owusu Boakye K (2025). RAGFlowChainR: Retrieval-Augmented Generation (RAG) Workflows R Local Web Search. R package version 0.1.1, https://github.com/knowusuboaky/RAGFlowChainR.","code":"@Manual{,   title = {RAGFlowChainR: Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search},   author = {Kwadwo Daddy Nyame {Owusu Boakye}},   year = {2025},   note = {R package version 0.1.1},   url = {https://github.com/knowusuboaky/RAGFlowChainR}, }"},{"path":[]},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"RAGFlowChainR R package brings Retrieval-Augmented Generation (RAG) capabilities R, inspired LangChain. enables intelligent retrieval documents local vector store (DuckDB), optional web search, seamless integration Large Language Models (LLMs). Features include: üìÇ Ingest files websites üîç Semantic search using vector embeddings üß† RAG chain execution conversational memory dynamic prompt construction üîå Plug--play OpenAI, Ollama, Groq, Anthropic Python version: RAGFlowChain (PyPI) GitHub (Python): RAGFlowChain","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"","code":"install.packages(\"RAGFlowChainR\")"},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"development-version","dir":"","previous_headings":"","what":"Development version","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"get latest features bug fixes, can install development version RAGFlowChainR GitHub: See full function reference package website details.","code":"# If needed install.packages(\"remotes\")  remotes::install_github(\"knowusuboaky/RAGFlowChainR\")"},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"id_-environment-setup","dir":"","previous_headings":"","what":"üîê Environment Setup","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"persist across sessions, add ~/.Renviron file.","code":"Sys.setenv(TAVILY_API_KEY    = \"your-tavily-api-key\") Sys.setenv(OPENAI_API_KEY    = \"your-openai-api-key\") Sys.setenv(GROQ_API_KEY      = \"your-groq-api-key\") Sys.setenv(ANTHROPIC_API_KEY = \"your-anthropic-api-key\")"},{"path":[]},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"id_1-data-ingestion","dir":"","previous_headings":"Usage","what":"1. Data Ingestion","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"","code":"library(RAGFlowChainR)  local_files <- c(\"tests/testthat/test-data/sprint.pdf\",                   \"tests/testthat/test-data/introduction.pptx\",                  \"tests/testthat/test-data/overview.txt\") website_urls <- c(\"https://www.r-project.org\") crawl_depth <- 1  response <- fetch_data(   local_paths = local_files,   website_urls = website_urls,   crawl_depth = crawl_depth ) response #>                                source                                      title ... #> 1                 documents/sprint.pdf                                       <NA> ... #> 2          documents/introduction.pptx                                       <NA> ... #> 3               documents/overview.txt                                       <NA> ... #> 4            https://www.r-project.org R: The R Project for Statistical Computing ... #> ...  cat(response$content[1]) #> Getting Started with Scrum\\nCodeWithPraveen.com ..."},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"id_2-vector-store--semantic-search","dir":"","previous_headings":"Usage","what":"2. Vector Store & Semantic Search","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"","code":"con <- create_vectorstore(\"tests/testthat/test-data/my_vectors.duckdb\", overwrite = TRUE)  docs <- data.frame(head(response))  # reuse from fetch_data()  insert_vectors(   con = con,   df = docs,   embed_fun = embed_openai(),   chunk_chars = 12000 )  build_vector_index(con, type = c(\"vss\", \"fts\"))  response <- search_vectors(con, query_text = \"Tell me about R?\", top_k = 5) response #>    id page_content                                                dist #> 1   5 [Home]\\nDownload\\nCRAN\\nR Project...\\n...                0.2183 #> 2   6 [Home]\\nDownload\\nCRAN\\nR Project...\\n...                0.2183 #> ...  cat(response$page_content[1]) #> [Home]\\nDownload\\nCRAN\\nR Project\\nAbout R\\nLogo\\n..."},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"id_3-rag-chain-querying","dir":"","previous_headings":"Usage","what":"3. RAG Chain Querying","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"","code":"rag_chain <- create_rag_chain(   llm = call_llm,   vector_database_directory = \"tests/testthat/test-data/my_vectors.duckdb\",   method = \"DuckDB\",   embedding_function = embed_openai(),   use_web_search = FALSE )  response <- rag_chain$invoke(\"Tell me about R\") response #> $input #> [1] \"Tell me about R\" #> #> $chat_history #> [[1]] $role: \"human\", $content: \"Tell me about R\" #> [[2]] $role: \"assistant\", $content: \"R is a programming language...\" #> #> $answer #> [1] \"R is a programming language and software environment commonly used for statistical computing and graphics...\"  cat(response$answer) #> R is a programming language and software environment commonly used for statistical computing and graphics..."},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"llm-support","dir":"","previous_headings":"","what":"LLM Support","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"","code":"call_llm(   prompt = \"Summarize the capital of France.\",   provider = \"groq\",   model = \"llama3-8b\",   temperature = 0.7,   max_tokens = 200 )"},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"id_-related-package-chatllm","dir":"","previous_headings":"","what":"üì¶ Related Package: chatLLM","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"chatLLM package (now available CRAN üéâ) offers modular interface interacting LLM providers including OpenAI, Groq, Anthropic. Features: üîÅ Seamless provider switching (openai, groq, anthropic) ‚úçÔ∏è Prompt + system message templating üí¨ Multi-message chat sessions üîå Native integration RAGFlowChainR üîê .Renviron-based key management","code":"install.packages(\"chatLLM\")"},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"MIT ¬© Kwadwo Daddy Nyame Owusu Boakye","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_rag_chain.html","id":null,"dir":"Reference","previous_headings":"","what":"create_rag_chain.R Overview ‚Äî create_rag_chain","title":"create_rag_chain.R Overview ‚Äî create_rag_chain","text":"refined implementation LangChain-style Retrieval-Augmented Generation (RAG) pipeline. Includes vector search using DuckDB, optional web search using Tavily API, built-chat message history. script powers `create_rag_chain()`, exported entry point constructing RAG pipeline. ## Features: - Context-aware reformulation user questions based chat history - Retrieval relevant chunks via semantic search - Optional real-time web search using Tavily (API key set) - Works LLM function (e.g., OpenAI, Claude) ## Required Packages Install : install.packages(c(\"DBI\", \"duckdb\", \"httr\", \"jsonlite\", \"stringi\", \"dplyr\")) Creates LangChain-style RAG chain using DuckDB vector store operations, optional Tavily API web search, -memory message history conversational context.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_rag_chain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"create_rag_chain.R Overview ‚Äî create_rag_chain","text":"","code":"create_rag_chain(   llm,   vector_database_directory,   method = \"DuckDB\",   embedding_function = NULL,   system_prompt = NULL,   chat_history_prompt = NULL,   tavily_search = NULL,   embedding_dim = 1536,   use_web_search = TRUE )"},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_rag_chain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"create_rag_chain.R Overview ‚Äî create_rag_chain","text":"llm function takes prompt returns response (e.g. call OpenAI Claude). vector_database_directory Path DuckDB database file. method Currently \"DuckDB\" supported. embedding_function function embedding text. Defaults `embed_openai()`. system_prompt Optional prompt placeholders {chat_history}, {input}, {context} chat_history_prompt Prompt used rephrase user questions based prior context. tavily_search API key Tavily (NULL disable web search). embedding_dim Dimensionality embedding vectors (default 1536). use_web_search Logical, whether include web results Tavily (default TRUE).","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_rag_chain.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"create_rag_chain.R Overview ‚Äî create_rag_chain","text":"list utility functions: invoke(text) ‚Äî Performs full context retrieval + LLM response custom_invoke(text) ‚Äî Retrieves context , LLM response get_session_history() ‚Äî Returns full chat history clear_history() ‚Äî Clears chat memory disconnect() ‚Äî Closes DuckDB connection","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_rag_chain.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"create_rag_chain.R Overview ‚Äî create_rag_chain","text":"`create_rag_chain()` exported.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_vectorstore.html","id":null,"dir":"Reference","previous_headings":"","what":"create_vectorstore.R ‚Äî Vector-store utilities ‚Äî create_vectorstore","title":"create_vectorstore.R ‚Äî Vector-store utilities ‚Äî create_vectorstore","text":"Tools ‚Ä¢ embed text OpenAI API ‚Ä¢ create DuckDB-backed vector store (optionally `vss` extension) ‚Ä¢ insert documents embeddings (handles chunking) ‚Ä¢ build HNSW/FTS indexes run nearest-neighbour search","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_vectorstore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"create_vectorstore.R ‚Äî Vector-store utilities ‚Äî create_vectorstore","text":"","code":"create_vectorstore(   db_path = \":memory:\",   overwrite = FALSE,   embedding_dim = 1536,   load_vss = identical(Sys.getenv(\"_R_CHECK_PACKAGE_NAME_\"), \"\") )"},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_vectorstore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"create_vectorstore.R ‚Äî Vector-store utilities ‚Äî create_vectorstore","text":"db_path Path DuckDB file (\\\"`:memory:`\\\" RAM). overwrite `TRUE`, delete existing file / table. embedding_dim Dimension embeddings stored. load_vss Try load experimental `vss` extension? Defaults `TRUE` except CRAN checks forced `FALSE`.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_vectorstore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"create_vectorstore.R ‚Äî Vector-store utilities ‚Äî create_vectorstore","text":"live `duckdb_connection`. Disconnect manually   `DBI::dbDisconnect(con, shutdown = TRUE)`.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_vectorstore.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"create_vectorstore.R ‚Äî Vector-store utilities ‚Äî create_vectorstore","text":"`create_vectorstore()` exported; helpers internal.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/data_fetcher.html","id":null,"dir":"Reference","previous_headings":"","what":"data_fetcher.R Overview ‚Äî data_fetcher","title":"data_fetcher.R Overview ‚Äî data_fetcher","text":"Provides `fetch_data()` function, extracts structures content : Local files (PDF, DOCX, PPTX, TXT, HTML) Crawled websites (optional BFS crawl depth) returned data frame includes metadata columns like `title`, `author`, `publishedDate`, main extracted `content`. ## Required Packages install.packages(c(\"pdftools\", \"officer\", \"rvest\", \"xml2\", \"dplyr\", \"stringi\", \"curl\", \"httr\", \"jsonlite\", \"magrittr\"))","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/data_fetcher.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"data_fetcher.R Overview ‚Äî data_fetcher","text":"`fetch_data()` exported. Internal functions include `read_local_file()`, `read_website_page()`, `crawl_links_bfs()`.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/fetch_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch Data from Local Files and Websites ‚Äî fetch_data","title":"Fetch Data from Local Files and Websites ‚Äî fetch_data","text":"Extracts content metadata local documents websites. Supports PDF, DOCX, PPTX, TXT, HTML files performs BFS web crawling specified depth.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/fetch_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch Data from Local Files and Websites ‚Äî fetch_data","text":"","code":"fetch_data(local_paths = NULL, website_urls = NULL, crawl_depth = NULL)"},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/fetch_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch Data from Local Files and Websites ‚Äî fetch_data","text":"local_paths character vector file paths directories scan documents. website_urls character vector website URLs crawl extract text . crawl_depth Integer indicating BFS crawl depth; set NULL infinite crawl.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/fetch_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch Data from Local Files and Websites ‚Äî fetch_data","text":"data frame following columns: source, title, author, publishedDate, description, content, url, source_type.","code":""}]
