[{"path":"https://knowusuboaky.github.io/RAGFlowChainR/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Kwadwo Daddy Nyame Owusu - Boakye Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kwadwo Daddy Nyame Owusu Boakye. Author, maintainer.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Owusu Boakye K (2025). RAGFlowChainR: Retrieval-Augmented Generation (RAG) Workflows R Local Web Search. R package version 0.1.2, https://github.com/knowusuboaky/RAGFlowChainR.","code":"@Manual{,   title = {RAGFlowChainR: Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search},   author = {Kwadwo Daddy Nyame {Owusu Boakye}},   year = {2025},   note = {R package version 0.1.2},   url = {https://github.com/knowusuboaky/RAGFlowChainR}, }"},{"path":[]},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"RAGFlowChainR R package brings Retrieval-Augmented Generation (RAG) capabilities R, inspired LangChain. enables intelligent retrieval documents local vector store (DuckDB), optional web search, seamless integration Large Language Models (LLMs). Features include: üìÇ Ingest files websites üîç Semantic search using vector embeddings üß† RAG chain execution conversational memory dynamic prompt construction üîå Plug--play OpenAI, Ollama, Groq, Anthropic Python version: RAGFlowChain (PyPI) GitHub (Python): RAGFlowChain","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"","code":"install.packages(\"RAGFlowChainR\")"},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"development-version","dir":"","previous_headings":"","what":"Development version","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"get latest features bug fixes, can install development version RAGFlowChainR GitHub: See full function reference package website details.","code":"# If needed install.packages(\"remotes\")  remotes::install_github(\"knowusuboaky/RAGFlowChainR\")"},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"id_-environment-setup","dir":"","previous_headings":"","what":"üîê Environment Setup","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"persist across sessions, add ~/.Renviron file.","code":"Sys.setenv(TAVILY_API_KEY    = \"your-tavily-api-key\") Sys.setenv(OPENAI_API_KEY    = \"your-openai-api-key\") Sys.setenv(GROQ_API_KEY      = \"your-groq-api-key\") Sys.setenv(ANTHROPIC_API_KEY = \"your-anthropic-api-key\")"},{"path":[]},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"id_1-data-ingestion","dir":"","previous_headings":"Usage","what":"1. Data Ingestion","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"","code":"library(RAGFlowChainR)  local_files <- c(\"tests/testthat/test-data/sprint.pdf\",                   \"tests/testthat/test-data/introduction.pptx\",                  \"tests/testthat/test-data/overview.txt\") website_urls <- c(\"https://www.r-project.org\") crawl_depth <- 1  response <- fetch_data(   local_paths = local_files,   website_urls = website_urls,   crawl_depth = crawl_depth ) response #>                                source                                      title ... #> 1                 documents/sprint.pdf                                       <NA> ... #> 2          documents/introduction.pptx                                       <NA> ... #> 3               documents/overview.txt                                       <NA> ... #> 4            https://www.r-project.org R: The R Project for Statistical Computing ... #> ...  cat(response$content[1]) #> Getting Started with Scrum\\nCodeWithPraveen.com ..."},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"id_2-vector-store--semantic-search","dir":"","previous_headings":"Usage","what":"2. Vector Store & Semantic Search","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"","code":"con <- create_vectorstore(\"tests/testthat/test-data/my_vectors.duckdb\", overwrite = TRUE)  docs <- data.frame(head(response))  # reuse from fetch_data()  insert_vectors(   con = con,   df = docs,   embed_fun = embed_openai(),   chunk_chars = 12000 )  build_vector_index(con, type = c(\"vss\", \"fts\"))  response <- search_vectors(con, query_text = \"Tell me about R?\", top_k = 5) response #>    id page_content                                                dist #> 1   5 [Home]\\nDownload\\nCRAN\\nR Project...\\n...                0.2183 #> 2   6 [Home]\\nDownload\\nCRAN\\nR Project...\\n...                0.2183 #> ...  cat(response$page_content[1]) #> [Home]\\nDownload\\nCRAN\\nR Project\\nAbout R\\nLogo\\n..."},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"id_3-rag-chain-querying","dir":"","previous_headings":"Usage","what":"3. RAG Chain Querying","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"","code":"rag_chain <- create_rag_chain(   llm = call_llm,   vector_database_directory = \"tests/testthat/test-data/my_vectors.duckdb\",   method = \"DuckDB\",   embedding_function = embed_openai(),   use_web_search = FALSE )  response <- rag_chain$invoke(\"Tell me about R\") response #> $input #> [1] \"Tell me about R\" #> #> $chat_history #> [[1]] $role: \"human\", $content: \"Tell me about R\" #> [[2]] $role: \"assistant\", $content: \"R is a programming language...\" #> #> $answer #> [1] \"R is a programming language and software environment commonly used for statistical computing and graphics...\"  cat(response$answer) #> R is a programming language and software environment commonly used for statistical computing and graphics..."},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"llm-support","dir":"","previous_headings":"","what":"LLM Support","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"","code":"call_llm(   prompt = \"Summarize the capital of France.\",   provider = \"groq\",   model = \"llama3-8b\",   temperature = 0.7,   max_tokens = 200 )"},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"id_-related-package-chatllm","dir":"","previous_headings":"","what":"üì¶ Related Package: chatLLM","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"chatLLM package (now available CRAN üéâ) offers modular interface interacting LLM providers including OpenAI, Groq, Anthropic. Features: üîÅ Seamless provider switching (openai, groq, anthropic) ‚úçÔ∏è Prompt + system message templating üí¨ Multi-message chat sessions üîå Native integration RAGFlowChainR üîê .Renviron-based key management","code":"install.packages(\"chatLLM\")"},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Retrieval-Augmented Generation (RAG) Workflows in R with Local and Web Search","text":"MIT ¬© Kwadwo Daddy Nyame Owusu Boakye","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_rag_chain.html","id":null,"dir":"Reference","previous_headings":"","what":"create_rag_chain.R Overview ‚Äî create_rag_chain","title":"create_rag_chain.R Overview ‚Äî create_rag_chain","text":"refined implementation LangChain-style Retrieval-Augmented Generation (RAG) pipeline. Includes vector search using DuckDB, optional web search using Tavily API, built-chat message history. function powers `create_rag_chain()`, exported entry point constructing full RAG pipeline. ## Features: - Context-aware reformulation user queries - Semantic chunk retrieval using DuckDB - Optional real-time web search (Tavily) - Compatible LLM function (OpenAI, Claude, etc.) ## Required Packages install.packages(c(\"DBI\", \"duckdb\", \"httr\", \"jsonlite\", \"stringi\", \"dplyr\"))","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_rag_chain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"create_rag_chain.R Overview ‚Äî create_rag_chain","text":"llm function takes prompt returns response (e.g. call OpenAI Claude). vector_database_directory Path DuckDB database file. method Retrieval method backend. Currently `\"DuckDB\"` supported. embedding_function function embed text. Defaults embed_openai(). system_prompt Optional prompt placeholders {chat_history}, {input}, {context}. chat_history_prompt Prompt used rephrase follow-questions using prior conversation history. tavily_search Tavily API key (set NULL disable web search). embedding_dim Integer; embedding vector dimension. Defaults 1536. use_web_search Logical; whether include web results Tavily. Defaults TRUE.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_rag_chain.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"create_rag_chain.R Overview ‚Äî create_rag_chain","text":"list utility functions: invoke(text) ‚Äî Performs full context retrieval LLM response custom_invoke(text) ‚Äî Retrieves context (LLM call) get_session_history() ‚Äî Returns complete conversation history clear_history() ‚Äî Clears -memory chat history disconnect() ‚Äî Closes underlying DuckDB connection","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_rag_chain.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"create_rag_chain.R Overview ‚Äî create_rag_chain","text":"Create Retrieval-Augmented Generation (RAG) Chain Creates LangChain-style RAG chain using DuckDB vector store operations, optional Tavily API web search, -memory message history conversational context.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_rag_chain.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"create_rag_chain.R Overview ‚Äî create_rag_chain","text":"create_rag_chain() exported. Helper functions internal.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_rag_chain.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"create_rag_chain.R Overview ‚Äî create_rag_chain","text":"","code":"if (FALSE) { # \\dontrun{ rag_chain <- create_rag_chain(   llm = call_llm,   vector_database_directory = \"tests/testthat/test-data/my_vectors.duckdb\",   method = \"DuckDB\",   embedding_function = embed_openai(),   use_web_search = FALSE )  response <- rag_chain$invoke(\"Tell me about R\") } # }"},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_vectorstore.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a DuckDB-based vector store ‚Äî create_vectorstore","title":"Create a DuckDB-based vector store ‚Äî create_vectorstore","text":"Initializes DuckDB database connection storing embedded documents, optional support experimental `vss` extension.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_vectorstore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a DuckDB-based vector store ‚Äî create_vectorstore","text":"db_path Path DuckDB file. Use `\":memory:\"` create -memory database. overwrite Logical; `TRUE`, deletes existing DuckDB file table. embedding_dim Integer; dimensionality vector embeddings store. load_vss Logical; whether load experimental `vss` extension. defaults `TRUE`, forced `FALSE` CRAN checks.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_vectorstore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a DuckDB-based vector store ‚Äî create_vectorstore","text":"live DuckDB connection object. sure manually disconnect : DBI::dbDisconnect(con, shutdown = TRUE)","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_vectorstore.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a DuckDB-based vector store ‚Äî create_vectorstore","text":"function part vector-store utilities : Embedding text via OpenAI API Storing chunking documents DuckDB Building `HNSW` `FTS` indexes Running nearest-neighbour search vector embeddings create_vectorstore() exported; helpers like insert_vectors(), build_vector_index(), search_vectors() internal designed composable.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/create_vectorstore.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a DuckDB-based vector store ‚Äî create_vectorstore","text":"","code":"if (FALSE) { # \\dontrun{ # Create vector store con <- create_vectorstore(\"tests/testthat/test-data/my_vectors.duckdb\", overwrite = TRUE)  # Assume response is output from fetch_data() docs <- data.frame(head(response))  # Insert documents with embeddings insert_vectors(   con = con,   df = docs,   embed_fun = embed_openai(),   chunk_chars = 12000 )  # Build vector + FTS indexes build_vector_index(con, type = c(\"vss\", \"fts\"))  # Perform vector search response <- search_vectors(con, query_text = \"Tell me about R?\", top_k = 5) } # }"},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/fetch_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch data from local files and websites ‚Äî fetch_data","title":"Fetch data from local files and websites ‚Äî fetch_data","text":"Extracts content metadata local documents websites. Supports: Local files: PDF, DOCX, PPTX, TXT, HTML Crawled websites: optional breadth-first crawl depth","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/fetch_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch data from local files and websites ‚Äî fetch_data","text":"local_paths character vector file paths directories scan documents. website_urls character vector website URLs crawl extract text . crawl_depth Integer indicating BFS crawl depth; use NULL unlimited depth.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/fetch_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch data from local files and websites ‚Äî fetch_data","text":"data frame extracted metadata content.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/fetch_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fetch data from local files and websites ‚Äî fetch_data","text":"returned data frame includes structured columns : source, title, author, publishedDate, description, content, url, source_type. ## Required Packages install.packages(c(\"pdftools\", \"officer\", \"rvest\", \"xml2\", \"dplyr\", \"stringi\", \"curl\", \"httr\", \"jsonlite\", \"magrittr\"))","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/fetch_data.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fetch data from local files and websites ‚Äî fetch_data","text":"Internal functions used include read_local_file(), read_website_page(), crawl_links_bfs().","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/reference/fetch_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fetch data from local files and websites ‚Äî fetch_data","text":"","code":"if (FALSE) { # \\dontrun{ local_files <- c(\"tests/testthat/test-data/sprint.pdf\",                  \"tests/testthat/test-data/introduction.pptx\",                  \"tests/testthat/test-data/overview.txt\") website_urls <- c(\"https://www.r-project.org\") crawl_depth <- 1  response <- fetch_data(   local_paths = local_files,   website_urls = website_urls,   crawl_depth = crawl_depth ) } # }"},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/news/index.html","id":"ragflowchainr-development-version","dir":"Changelog","previous_headings":"","what":"RAGFlowChainR (development version)","title":"RAGFlowChainR (development version)","text":"Wrapped FTS-related tests tryCatch() + skip() avoid segmentation faults Fedora-clang CRAN checks. Informative skip() messages added systems without FTS extension support. Ensured tests pass cleanly platforms partial DuckDB extension support. Maintained full feature test coverage interactive/development environments. user-facing changes exported API modifications.","code":""},{"path":"https://knowusuboaky.github.io/RAGFlowChainR/news/index.html","id":"ragflowchainr-011","dir":"Changelog","previous_headings":"","what":"RAGFlowChainR 0.1.1","title":"RAGFlowChainR 0.1.1","text":"CRAN release: 2025-04-24 Prevented segfaults CRAN disabling experimental vss extension checks. Fallback FLOAT[] column type vss unavailable, avoiding Fedora-clang binary-extension errors. create_vectorstore() now: Skips vss installation/loading CRAN retains support dev environments. Returns persistent DuckDB connection (longer auto-disconnects). insert_vectors(): Handles single-column frames safely using drop = FALSE. Dynamically switches array_value() list_value() based schema. build_vector_index(): Skips HNSW index creation VECTOR[] columns missing (warning). RAG chain integration: Safely mirrors vss-guard logic connect_vectorstore() create_rag_chain(). DESCRIPTION metadata: Set minimum required version: duckdb (>= 0.10.0) testthat (>= 3.0.0). Added Config/testthat/edition: 3 consistent test behavior. Tidied Description field removing unnecessary single quotes around names. Expanded common acronyms like HNSW, LLM, etc. Testing improvements: Suppressed non-critical test warnings. Removed fragile FTS assertions (fts_main). Introduced mock_embed() dummy_embed() remove dependency external APIs. Skipped RAG-chain integration tests CRAN gated test-data downloads.","code":""}]
